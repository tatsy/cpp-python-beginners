{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUP8YUdF6oQ8",
        "outputId": "ea1655b6-cb58-4588-b603-95f10c53c7e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n"
          ]
        }
      ],
      "source": [
        "# 必要なパッケージのインストール\n",
        "!pip install torch torchvision\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrivS6eI6xrk",
        "outputId": "a5ee7084-d738-4caa-8129-5063e88c247b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Google Driveとのデータのやり取り\n",
        "from google.colab import drive\n",
        "drive_dir = '/content/drive'\n",
        "drive.mount(drive_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8BQRWv965Lz"
      },
      "outputs": [],
      "source": [
        "# パッケージのインストール\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "import struct\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSTggVFr7F7T"
      },
      "outputs": [],
      "source": [
        "# よく使うファイル・ディレクトリ\n",
        "colab_dir = os.path.join(drive_dir, 'My Drive', 'Colab Notebooks')\n",
        "model_path = os.path.join(colab_dir, 'DCGAN_mnist.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywD8U9hy7KOD"
      },
      "outputs": [],
      "source": [
        "# データセットの読み取り\n",
        "class MnistDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_dir, mode='train'):\n",
        "        super(MnistDataset, self).__init__()\n",
        "\n",
        "        self.root_dir = root_dir\n",
        "        self.mode = mode\n",
        "        self.n_classes = 10\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self.image_file = 'train-images-idx3-ubyte'\n",
        "            self.label_file = 'train-labels-idx1-ubyte'\n",
        "        elif self.mode == 'test':\n",
        "            self.image_file = 't10k-images-idx3-ubyte'\n",
        "            self.label_file = 't10k-labels-idx1-ubyte'\n",
        "        else:\n",
        "            raise Exception('MNIST dataset mode must be \"train\" or \"test\"')\n",
        "        \n",
        "        self.image_data = self._load_images(os.path.join(self.root_dir, self.image_file))\n",
        "        self.label_data = self._load_labels(os.path.join(self.root_dir, self.label_file))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'images': self.image_data[idx],\n",
        "            'labels': self.label_data[idx]\n",
        "        }\n",
        "\n",
        "    def _load_images(self, filename):\n",
        "        with open(filename, 'rb') as fp:\n",
        "            magic = struct.unpack('>i', fp.read(4))[0]\n",
        "            if magic != 2051:\n",
        "                raise Exception('Magic number does not match!')\n",
        "\n",
        "            n_images, height, width = struct.unpack('>iii', fp.read(4 * 3))\n",
        "\n",
        "            n_pixels = n_images * height * width\n",
        "            pixels = struct.unpack('>' + 'B' * n_pixels, fp.read(n_pixels))\n",
        "            pixels = np.asarray(pixels, dtype='uint8').reshape((n_images, 1, height, width))\n",
        "\n",
        "            # 画像サイズを2べきにしておく\n",
        "            pixels = np.pad(pixels, [(0, 0), (0, 0), (2, 2), (2, 2)], mode='constant', constant_values=0)\n",
        "            pixels = (pixels / 255.0).astype('float32')\n",
        "\n",
        "        return pixels\n",
        "\n",
        "    def _load_labels(self, filename):\n",
        "        with open(filename, 'rb') as fp:\n",
        "            magic = struct.unpack('>i', fp.read(4))[0]\n",
        "            if magic != 2049:\n",
        "                raise Exception('Magic number does not match!')\n",
        "\n",
        "            n_labels = struct.unpack('>i', fp.read(4))[0]\n",
        "            labels = struct.unpack('>' + 'B' * n_labels, fp.read(n_labels))\n",
        "            labels = np.asarray(labels, dtype='int64')\n",
        "\n",
        "        return labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LtSv3_-IHF4"
      },
      "outputs": [],
      "source": [
        "# 基本処理\n",
        "class BlockG(nn.Module):\n",
        "    \"\"\" Basic convolution block for generator (Conv, BN, ReLU) \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(BlockG, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class BlockD(nn.Module):\n",
        "    \"\"\" Basic convolution block for discriminator (Conv, LeakyReLU) \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(BlockD, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\" Up-sampling \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Up, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\" Down-sampling \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Down, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQPNQ1GEH1TU"
      },
      "outputs": [],
      "source": [
        "# Generatorの定義\n",
        "class NetG(nn.Module):\n",
        "    def __init__(self, in_features=128, out_channels=3, base_filters=8):\n",
        "        super(NetG, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_channels = out_channels\n",
        "        self.base_filters = base_filters\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.in_features, self.base_filters * 8,\n",
        "                                kernel_size=4, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(self.base_filters * 8),\n",
        "            nn.ReLU(inplace=True),\n",
        "            Up(self.base_filters * 8, self.base_filters * 4),\n",
        "            Up(self.base_filters * 4, self.base_filters * 2),\n",
        "            Up(self.base_filters * 2, self.base_filters * 1),\n",
        "            nn.Conv2d(base_filters * 1, self.out_channels,\n",
        "                      kernel_size=3, stride=1, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        n_batches, n_dims = x.size()\n",
        "        x = x.view(n_batches, n_dims, 1, 1)\n",
        "        for conv in self.net:\n",
        "            x = conv(x)\n",
        "        return torch.tanh(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oTTmN6eKhW8"
      },
      "outputs": [],
      "source": [
        "# Discriminatorの定義\n",
        "class NetD(nn.Module):\n",
        "    def __init__(self, in_channels=3, base_filters=8):\n",
        "        super(NetD, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.base_filters = base_filters\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            BlockD(self.in_channels, self.base_filters),\n",
        "            Down(self.base_filters, self.base_filters * 2),\n",
        "            Down(self.base_filters * 2, self.base_filters * 4),\n",
        "            Down(self.base_filters * 4, self.base_filters * 8),\n",
        "            nn.Conv2d(self.base_filters * 8, 1, kernel_size=4, stride=1, padding=0)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        return x.squeeze()  # BCELossWithLogitsを使うのでsigmoidに入れない"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6E1xjTYtaEy"
      },
      "outputs": [],
      "source": [
        "def to_onehot(cls, n_classes):\n",
        "    ident = torch.eye(n_classes, dtype=torch.float32, device=cls.device)\n",
        "    return ident[cls]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFNb5_oJNZkx",
        "outputId": "8832b6aa-cae4-4191-af3e-16239097ca56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# 使用するデバイスの設定\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda', 0)\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print('Device: {}'.format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8XhJGjPOxsf"
      },
      "outputs": [],
      "source": [
        "# 各種パラメータ\n",
        "sample_dims = 32            # zの次元\n",
        "base_lr = 2.0e-4            # 学習率\n",
        "beta1 = 0.5                 # Adamのbeta1\n",
        "beta2 = 0.9                 # Adamのbeta2\n",
        "base_filters = 8            # CNNの基本チャンネル数\n",
        "data_root = 'MNIST'  # データセットのディレクトリ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVkaDYaCOimi",
        "outputId": "939f3c57-7163-4e2a-ff05-fcfbfe97b2ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "# データセットローダの準備\n",
        "dataset = MnistDataset(os.path.join(colab_dir, data_root))\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=25, num_workers=4, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OM0m9QqNe_j"
      },
      "outputs": [],
      "source": [
        "# ネットワークとoptimizerの定義\n",
        "n_classes = dataset.n_classes\n",
        "netD = NetD(in_channels=1 + n_classes, base_filters=base_filters)\n",
        "netG = NetG(in_features=sample_dims + n_classes, out_channels=1, base_filters=base_filters)\n",
        "netD.to(device)\n",
        "netG.to(device)\n",
        "optimD = torch.optim.Adam(netD.parameters(), lr=base_lr, betas=(beta1, beta2))\n",
        "optimG = torch.optim.Adam(netG.parameters(), lr=base_lr, betas=(beta1, beta2))\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# モデルファイルの読み込み (続きから学習するときはreload_modelをTrueにする)\n",
        "reload_model = False\n",
        "start_epoch = 0\n",
        "start_steps = 0\n",
        "if reload_model:\n",
        "    ckpt = torch.load(model_path)\n",
        "    optimG.load_state_dict(ckpt['optimG'])\n",
        "    optimD.load_state_dict(ckpt['optimD'])\n",
        "    netG.load_state_dict(ckpt['netG'])\n",
        "    netD.load_state_dict(ckpt['netD'])\n",
        "    start_epoch = ckpt['epoch']\n",
        "    start_steps = ckpt['steps']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMS-rz0GOFPS"
      },
      "outputs": [],
      "source": [
        "# 学習の途中経過を保存するフォルダの作成\n",
        "now = datetime.datetime.now()\n",
        "time_stamp = now.strftime('%Y%m%d-%H%M%S')\n",
        "runs_dir = os.path.join(colab_dir, 'runs')\n",
        "log_dir = os.path.join(runs_dir, time_stamp)\n",
        "os.makedirs(log_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvDEdUxsPPhy",
        "outputId": "a13b544b-69d6-4d27-ec23-b335ac04d015"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2400 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch #0, 2399 steps, lossD=0.9565, lossG=1.0555: 100%|██████████| 2400/2400 [00:49<00:00, 48.61it/s]\n",
            "epoch #1, 4799 steps, lossD=1.1848, lossG=0.6473: 100%|██████████| 2400/2400 [00:47<00:00, 50.34it/s]\n",
            "epoch #2, 7199 steps, lossD=0.9570, lossG=0.6864: 100%|██████████| 2400/2400 [00:48<00:00, 49.98it/s]\n",
            "epoch #3, 9599 steps, lossD=1.5152, lossG=0.9667: 100%|██████████| 2400/2400 [00:47<00:00, 50.60it/s]\n",
            "epoch #4, 11999 steps, lossD=0.9248, lossG=1.0520: 100%|██████████| 2400/2400 [00:47<00:00, 50.45it/s]\n",
            "epoch #5, 14399 steps, lossD=0.9998, lossG=1.0292: 100%|██████████| 2400/2400 [00:47<00:00, 50.45it/s]\n",
            "epoch #6, 16799 steps, lossD=1.2674, lossG=2.2031: 100%|██████████| 2400/2400 [00:47<00:00, 50.70it/s]\n",
            "epoch #7, 19199 steps, lossD=1.1176, lossG=1.3245: 100%|██████████| 2400/2400 [00:47<00:00, 50.65it/s]\n",
            "epoch #8, 21599 steps, lossD=0.5243, lossG=2.6681: 100%|██████████| 2400/2400 [00:47<00:00, 50.11it/s]\n",
            "epoch #9, 23999 steps, lossD=0.6172, lossG=2.4913: 100%|██████████| 2400/2400 [00:47<00:00, 50.04it/s]\n",
            "epoch #10, 26399 steps, lossD=0.5429, lossG=3.5811: 100%|██████████| 2400/2400 [00:47<00:00, 50.41it/s]\n",
            "epoch #11, 28799 steps, lossD=0.4760, lossG=1.7816: 100%|██████████| 2400/2400 [00:47<00:00, 50.32it/s]\n",
            "epoch #12, 31199 steps, lossD=0.5527, lossG=2.2159: 100%|██████████| 2400/2400 [00:48<00:00, 49.36it/s]\n",
            "epoch #13, 33599 steps, lossD=0.3564, lossG=2.0115: 100%|██████████| 2400/2400 [00:49<00:00, 48.45it/s]\n",
            "epoch #14, 35999 steps, lossD=0.6083, lossG=2.6608: 100%|██████████| 2400/2400 [00:50<00:00, 47.28it/s]\n",
            "epoch #15, 38399 steps, lossD=0.5635, lossG=2.8192: 100%|██████████| 2400/2400 [00:50<00:00, 47.98it/s]\n",
            "epoch #16, 40799 steps, lossD=0.4002, lossG=2.0199: 100%|██████████| 2400/2400 [00:49<00:00, 48.06it/s]\n",
            "epoch #17, 43199 steps, lossD=0.4543, lossG=2.1908: 100%|██████████| 2400/2400 [00:49<00:00, 48.47it/s]\n",
            "epoch #18, 45599 steps, lossD=0.5628, lossG=2.5175: 100%|██████████| 2400/2400 [00:49<00:00, 48.31it/s]\n",
            "epoch #19, 47999 steps, lossD=0.5429, lossG=0.6761: 100%|██████████| 2400/2400 [00:49<00:00, 48.68it/s]\n",
            "epoch #20, 50399 steps, lossD=0.2674, lossG=3.8981: 100%|██████████| 2400/2400 [00:49<00:00, 48.59it/s]\n",
            "epoch #21, 52799 steps, lossD=0.4027, lossG=3.0516: 100%|██████████| 2400/2400 [00:49<00:00, 48.17it/s]\n",
            "epoch #22, 55199 steps, lossD=0.4268, lossG=2.6971: 100%|██████████| 2400/2400 [00:49<00:00, 48.17it/s]\n",
            "epoch #23, 57599 steps, lossD=0.2854, lossG=1.3530: 100%|██████████| 2400/2400 [00:49<00:00, 48.34it/s]\n",
            "epoch #24, 59999 steps, lossD=0.3808, lossG=1.7470: 100%|██████████| 2400/2400 [00:51<00:00, 46.79it/s]\n",
            "epoch #25, 62399 steps, lossD=1.2544, lossG=0.3694: 100%|██████████| 2400/2400 [00:50<00:00, 47.75it/s]\n",
            "epoch #26, 64799 steps, lossD=0.1636, lossG=0.8249: 100%|██████████| 2400/2400 [00:49<00:00, 48.32it/s]\n",
            "epoch #27, 67199 steps, lossD=0.4851, lossG=4.4969: 100%|██████████| 2400/2400 [00:49<00:00, 48.29it/s]\n",
            "epoch #28, 69599 steps, lossD=0.6101, lossG=1.2666: 100%|██████████| 2400/2400 [00:49<00:00, 48.22it/s]\n",
            "epoch #29, 71999 steps, lossD=0.3641, lossG=0.6154: 100%|██████████| 2400/2400 [00:49<00:00, 48.70it/s]\n",
            "epoch #30, 74399 steps, lossD=0.5210, lossG=2.4628: 100%|██████████| 2400/2400 [00:49<00:00, 48.43it/s]\n",
            "epoch #31, 76799 steps, lossD=0.9883, lossG=1.6475: 100%|██████████| 2400/2400 [00:49<00:00, 48.46it/s]\n",
            "epoch #32, 79199 steps, lossD=1.5363, lossG=0.8706: 100%|██████████| 2400/2400 [00:49<00:00, 48.35it/s]\n",
            "epoch #33, 81599 steps, lossD=0.6257, lossG=3.7593: 100%|██████████| 2400/2400 [00:49<00:00, 48.21it/s]\n",
            "epoch #34, 83999 steps, lossD=0.3850, lossG=1.3917: 100%|██████████| 2400/2400 [00:49<00:00, 48.41it/s]\n",
            "epoch #35, 86399 steps, lossD=0.2314, lossG=2.2245: 100%|██████████| 2400/2400 [00:49<00:00, 48.23it/s]\n",
            "epoch #36, 88799 steps, lossD=0.4660, lossG=2.4439: 100%|██████████| 2400/2400 [00:49<00:00, 48.28it/s]\n",
            "epoch #37, 91199 steps, lossD=0.4912, lossG=2.2741: 100%|██████████| 2400/2400 [00:50<00:00, 47.89it/s]\n",
            "epoch #38, 93599 steps, lossD=0.4628, lossG=1.1111: 100%|██████████| 2400/2400 [00:50<00:00, 47.45it/s]\n",
            "epoch #39, 95999 steps, lossD=0.3508, lossG=2.9499: 100%|██████████| 2400/2400 [00:50<00:00, 47.95it/s]\n",
            "epoch #40, 98399 steps, lossD=1.2932, lossG=2.7078: 100%|██████████| 2400/2400 [00:49<00:00, 48.24it/s]\n",
            "epoch #41, 100799 steps, lossD=0.3621, lossG=1.5326: 100%|██████████| 2400/2400 [00:49<00:00, 48.87it/s]\n",
            "epoch #42, 103199 steps, lossD=0.5270, lossG=0.6792: 100%|██████████| 2400/2400 [00:49<00:00, 48.69it/s]\n",
            "epoch #43, 105599 steps, lossD=0.8350, lossG=1.3254: 100%|██████████| 2400/2400 [00:49<00:00, 48.69it/s]\n",
            "epoch #44, 107999 steps, lossD=0.2531, lossG=2.8175: 100%|██████████| 2400/2400 [00:49<00:00, 48.90it/s]\n",
            "epoch #45, 110399 steps, lossD=0.7601, lossG=2.1136: 100%|██████████| 2400/2400 [00:49<00:00, 48.19it/s]\n",
            "epoch #46, 112799 steps, lossD=0.4197, lossG=3.3628: 100%|██████████| 2400/2400 [00:49<00:00, 48.64it/s]\n",
            "epoch #47, 115199 steps, lossD=0.6039, lossG=3.4454: 100%|██████████| 2400/2400 [00:49<00:00, 48.45it/s]\n",
            "epoch #48, 117599 steps, lossD=0.2578, lossG=3.0822: 100%|██████████| 2400/2400 [00:49<00:00, 48.67it/s]\n",
            "epoch #49, 119999 steps, lossD=0.4238, lossG=1.8694: 100%|██████████| 2400/2400 [00:49<00:00, 48.95it/s]\n",
            "epoch #50, 122399 steps, lossD=0.5649, lossG=2.1223: 100%|██████████| 2400/2400 [00:49<00:00, 48.60it/s]\n",
            "epoch #51, 124799 steps, lossD=0.3704, lossG=2.2619: 100%|██████████| 2400/2400 [00:49<00:00, 48.50it/s]\n",
            "epoch #52, 127199 steps, lossD=0.4505, lossG=1.9445: 100%|██████████| 2400/2400 [00:49<00:00, 48.45it/s]\n",
            "epoch #53, 129599 steps, lossD=0.5815, lossG=1.2049: 100%|██████████| 2400/2400 [00:49<00:00, 48.43it/s]\n",
            "epoch #54, 131999 steps, lossD=0.2330, lossG=1.3553: 100%|██████████| 2400/2400 [00:49<00:00, 48.24it/s]\n",
            "epoch #55, 134399 steps, lossD=0.6680, lossG=3.1024: 100%|██████████| 2400/2400 [00:49<00:00, 48.51it/s]\n",
            "epoch #56, 136799 steps, lossD=0.4107, lossG=2.2347: 100%|██████████| 2400/2400 [00:49<00:00, 48.67it/s]\n",
            "epoch #57, 139199 steps, lossD=0.3889, lossG=4.0403: 100%|██████████| 2400/2400 [00:49<00:00, 48.06it/s]\n",
            "epoch #58, 141599 steps, lossD=0.1249, lossG=2.7034: 100%|██████████| 2400/2400 [00:49<00:00, 48.49it/s]\n",
            "epoch #59, 143999 steps, lossD=0.1337, lossG=4.3278: 100%|██████████| 2400/2400 [00:49<00:00, 48.41it/s]\n",
            "epoch #60, 146399 steps, lossD=0.2376, lossG=3.0098: 100%|██████████| 2400/2400 [00:49<00:00, 48.33it/s]\n",
            "epoch #61, 148799 steps, lossD=0.3183, lossG=3.4306: 100%|██████████| 2400/2400 [00:50<00:00, 47.70it/s]\n",
            "epoch #62, 151199 steps, lossD=0.5367, lossG=1.9944: 100%|██████████| 2400/2400 [00:50<00:00, 47.80it/s]\n",
            "epoch #63, 153599 steps, lossD=0.8578, lossG=1.7585: 100%|██████████| 2400/2400 [00:50<00:00, 47.92it/s]\n",
            "epoch #64, 155999 steps, lossD=0.3181, lossG=0.7292: 100%|██████████| 2400/2400 [00:49<00:00, 48.32it/s]\n",
            "epoch #65, 158399 steps, lossD=0.3308, lossG=3.4280: 100%|██████████| 2400/2400 [00:49<00:00, 48.36it/s]\n",
            "epoch #66, 160799 steps, lossD=0.6813, lossG=2.0729: 100%|██████████| 2400/2400 [00:49<00:00, 48.61it/s]\n",
            "epoch #67, 163199 steps, lossD=0.5289, lossG=2.4487: 100%|██████████| 2400/2400 [00:50<00:00, 47.26it/s]\n",
            "epoch #68, 165599 steps, lossD=0.1545, lossG=1.2140: 100%|██████████| 2400/2400 [00:48<00:00, 49.14it/s]\n",
            "epoch #69, 167999 steps, lossD=0.6641, lossG=3.4183: 100%|██████████| 2400/2400 [00:47<00:00, 50.91it/s]\n",
            "epoch #70, 170399 steps, lossD=1.2762, lossG=2.4454: 100%|██████████| 2400/2400 [00:46<00:00, 51.54it/s]\n",
            "epoch #71, 172799 steps, lossD=0.4264, lossG=0.8473: 100%|██████████| 2400/2400 [00:46<00:00, 51.20it/s]\n",
            "epoch #72, 175199 steps, lossD=0.2517, lossG=2.4648: 100%|██████████| 2400/2400 [00:46<00:00, 51.50it/s]\n",
            "epoch #73, 177599 steps, lossD=0.2423, lossG=2.6344: 100%|██████████| 2400/2400 [00:46<00:00, 51.28it/s]\n",
            "epoch #74, 179999 steps, lossD=0.2914, lossG=2.2848: 100%|██████████| 2400/2400 [00:48<00:00, 49.90it/s]\n",
            "epoch #75, 182399 steps, lossD=0.2345, lossG=2.3384: 100%|██████████| 2400/2400 [00:51<00:00, 46.42it/s]\n",
            "epoch #76, 184799 steps, lossD=0.8066, lossG=3.7138: 100%|██████████| 2400/2400 [00:51<00:00, 46.78it/s]\n",
            "epoch #77, 187199 steps, lossD=0.2276, lossG=3.2362: 100%|██████████| 2400/2400 [00:52<00:00, 45.84it/s]\n",
            "epoch #78, 189599 steps, lossD=0.4136, lossG=1.7585: 100%|██████████| 2400/2400 [00:51<00:00, 46.78it/s]\n",
            "epoch #79, 191999 steps, lossD=0.1650, lossG=3.2231: 100%|██████████| 2400/2400 [00:50<00:00, 47.82it/s]\n",
            "epoch #80, 194399 steps, lossD=0.2282, lossG=4.5698: 100%|██████████| 2400/2400 [00:50<00:00, 47.49it/s]\n",
            "epoch #81, 196799 steps, lossD=0.0909, lossG=1.4105: 100%|██████████| 2400/2400 [00:48<00:00, 49.41it/s]\n",
            "epoch #82, 199199 steps, lossD=0.7061, lossG=2.2985: 100%|██████████| 2400/2400 [00:48<00:00, 49.16it/s]\n",
            "epoch #83, 201599 steps, lossD=0.8385, lossG=3.6922: 100%|██████████| 2400/2400 [00:47<00:00, 50.35it/s]\n",
            "epoch #84, 203999 steps, lossD=0.6775, lossG=4.9932: 100%|██████████| 2400/2400 [00:47<00:00, 50.27it/s]\n",
            "epoch #85, 206399 steps, lossD=1.2943, lossG=1.3590: 100%|██████████| 2400/2400 [00:48<00:00, 49.94it/s]\n",
            "epoch #86, 208799 steps, lossD=0.0339, lossG=3.0628: 100%|██████████| 2400/2400 [00:48<00:00, 49.53it/s]\n",
            "epoch #87, 211199 steps, lossD=0.3214, lossG=3.1067: 100%|██████████| 2400/2400 [00:48<00:00, 49.85it/s]\n",
            "epoch #88, 213599 steps, lossD=0.5524, lossG=2.9939: 100%|██████████| 2400/2400 [00:46<00:00, 51.22it/s]\n",
            "epoch #89, 215999 steps, lossD=0.1440, lossG=1.7233: 100%|██████████| 2400/2400 [00:48<00:00, 49.51it/s]\n",
            "epoch #90, 218399 steps, lossD=0.2763, lossG=1.8824: 100%|██████████| 2400/2400 [00:50<00:00, 47.55it/s]\n",
            "epoch #91, 220799 steps, lossD=0.1856, lossG=3.5340: 100%|██████████| 2400/2400 [00:49<00:00, 48.72it/s]\n",
            "epoch #92, 223199 steps, lossD=0.1495, lossG=3.4744: 100%|██████████| 2400/2400 [00:47<00:00, 50.29it/s]\n",
            "epoch #93, 225599 steps, lossD=0.6117, lossG=2.6680: 100%|██████████| 2400/2400 [00:46<00:00, 51.18it/s]\n",
            "epoch #94, 227999 steps, lossD=0.1268, lossG=4.8133: 100%|██████████| 2400/2400 [00:47<00:00, 50.58it/s]\n",
            "epoch #95, 230399 steps, lossD=0.1886, lossG=3.3656: 100%|██████████| 2400/2400 [00:47<00:00, 50.79it/s]\n",
            "epoch #96, 232799 steps, lossD=0.3078, lossG=5.9334: 100%|██████████| 2400/2400 [00:47<00:00, 51.02it/s]\n",
            "epoch #97, 235199 steps, lossD=0.3820, lossG=5.6682: 100%|██████████| 2400/2400 [00:47<00:00, 50.11it/s]\n",
            "epoch #98, 237599 steps, lossD=1.1647, lossG=3.1032: 100%|██████████| 2400/2400 [00:47<00:00, 50.54it/s]\n",
            "epoch #99, 239999 steps, lossD=0.0955, lossG=5.3523: 100%|██████████| 2400/2400 [00:47<00:00, 50.65it/s]\n"
          ]
        }
      ],
      "source": [
        "# 学習ループ\n",
        "steps = start_steps\n",
        "for epoch in range(start_epoch, 100):\n",
        "    tqdm_iter = tqdm(data_loader, file=sys.stdout)\n",
        "    for data in tqdm_iter:\n",
        "        x_real = data['images'].to(device)\n",
        "        c_real = data['labels'].to(device)\n",
        "        n_batches, _, height, width = x_real.size()\n",
        "\n",
        "        x_real = 2.0 * x_real - 1.0\n",
        "        c_onehot = to_onehot(c_real, n_classes)\n",
        "        c_onehot_tile = c_onehot.view(n_batches, -1, 1, 1).repeat(1, 1, height, width)\n",
        "\n",
        "        netD.train()\n",
        "        netG.train()\n",
        "\n",
        "        # Discriminatorの学習\n",
        "        optimD.zero_grad()\n",
        "\n",
        "        z = torch.randn([n_batches, sample_dims], dtype=torch.float32, device=device)\n",
        "        z = torch.cat([z, c_onehot], dim=1)\n",
        "        x_fake = netG(z)\n",
        "        x_fake = x_fake.detach()\n",
        "        y_fake = netD(torch.cat([x_fake, c_onehot_tile], dim=1))\n",
        "        y_real = netD(torch.cat([x_real, c_onehot_tile], dim=1))\n",
        "\n",
        "        lossD = criterion(y_fake, torch.zeros_like(y_fake)) +\\\n",
        "                criterion(y_real, torch.ones_like(y_real))\n",
        "        lossD.backward()\n",
        "\n",
        "        optimD.step()\n",
        "\n",
        "        # Generatorの学習\n",
        "        optimG.zero_grad()\n",
        "\n",
        "        z = torch.randn([n_batches, sample_dims], dtype=torch.float32, device=device)\n",
        "        z = torch.cat([z, c_onehot], dim=1)\n",
        "        x_fake = netG(z)\n",
        "        y_fake = netD(torch.cat([x_fake, c_onehot_tile], dim=1))\n",
        "\n",
        "        lossG = criterion(y_fake, torch.ones_like(y_fake))\n",
        "        lossG.backward()\n",
        "\n",
        "        optimG.step()\n",
        "\n",
        "        # ロスを標準出力する\n",
        "        tqdm_iter.set_description(\"epoch #{:d}, {:d} steps, lossD={:.4f}, lossG={:.4f}\".format(epoch, steps, lossD.item(), lossG.item()))\n",
        "\n",
        "        # 途中経過の保存\n",
        "        if steps % 50 == 0:\n",
        "            outfile = os.path.join(log_dir, 'x_real_{:03d}.jpg'.format(epoch))\n",
        "            torchvision.utils.save_image(x_real * 0.5 + 0.5, outfile, nrow=5, padding=10)\n",
        "            outfile = os.path.join(log_dir, 'x_fake_{:03d}.jpg'.format(epoch))\n",
        "            torchvision.utils.save_image(x_fake * 0.5 + 0.5, outfile, nrow=5, padding=10)\n",
        "\n",
        "            netG.eval()\n",
        "            z = torch.randn([n_classes, sample_dims], dtype=torch.float32).to(device)\n",
        "            c_onehot = torch.eye(n_classes, dtype=torch.float32).to(device)\n",
        "            z = torch.cat([z, c_onehot], dim=1)\n",
        "            x_fake = netG(z)\n",
        "            \n",
        "            outfile = os.path.join(log_dir, 'x_fake_class_{:03d}.jpg'.format(epoch))\n",
        "            torchvision.utils.save_image(x_fake * 0.5 + 0.5, outfile, nrow=5, padding=10)\n",
        "\n",
        "\n",
        "        steps += 1\n",
        "\n",
        "    # 学習途中のモデルを保存\n",
        "    ckpt = {\n",
        "        'optimG': optimG.state_dict(),\n",
        "        'optimD': optimD.state_dict(),\n",
        "        'netG': netG.state_dict(),\n",
        "        'netD': netD.state_dict(),\n",
        "        'epoch': epoch,\n",
        "        'steps': steps\n",
        "    }\n",
        "    torch.save(ckpt, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "plJ85-yWRgFJ"
      },
      "outputs": [],
      "source": [
        "# 10x10の画像を作る\n",
        "n_samples = 10\n",
        "\n",
        "netG.eval()\n",
        "\n",
        "z = torch.randn([n_samples, sample_dims], dtype=torch.float32, device=device)\n",
        "z = z.repeat(1, n_classes).view(-1, sample_dims)\n",
        "c_onehot = torch.eye(n_classes, dtype=torch.float32).to(device)\n",
        "c_onehot = c_onehot.repeat(n_samples, 1)\n",
        "\n",
        "z_and_c = torch.cat([z, c_onehot], dim=1)\n",
        "x_fake = netG(z_and_c)\n",
        "\n",
        "outfile = os.path.join(log_dir, 'x_fake_class_tile.jpg'.format(epoch))\n",
        "torchvision.utils.save_image(x_fake * 0.5 + 0.5, outfile, nrow=n_samples, padding=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p-6j4tmPVjCW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DCGAN_mnist_class.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}